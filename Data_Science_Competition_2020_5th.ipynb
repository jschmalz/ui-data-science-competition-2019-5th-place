{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_fea, out_fea, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.block=nn.Sequential(nn.Conv2d(in_fea, out_fea, 3, padding=1, stride=stride, bias=False),\n",
    "                               nn.BatchNorm2d(out_fea),\n",
    "                               nn.Dropout(0.1),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(out_fea, out_fea, 3, padding=1),\n",
    "                               nn.BatchNorm2d(out_fea),\n",
    "                               )\n",
    "        b=[nn.Conv2d(in_fea, out_fea, 1)]\n",
    "        if stride>1:\n",
    "            b.append(nn.MaxPool2d(stride))\n",
    "        self.shortcut=nn.Sequential(*b)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.block(x)+self.shortcut(x)\n",
    "        return F.relu(x)  \n",
    "        \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, features, strides, num_class=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        b = [BasicBlock(fea_in, fea_out, stri) for fea_in, fea_out, stri in zip(features[:-1], features[1:], strides)]\n",
    "        self.layers=nn.Sequential(*b)\n",
    "        self.last=nn.Linear(features[-1],num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.layers(x)\n",
    "        N,C,h,w=x.shape\n",
    "        x=F.max_pool2d(x,(h,w))\n",
    "        x=self.last(x.view(x.shape[0],-1))\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(epoch, to_print=True):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    if to_print:\n",
    "        print('epoch %d Train loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (epoch+1, train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "def test(epoch):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    print('        Test loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "        % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('Competition_Train_data_40000_dist.npy')\n",
    "y=np.load('Competition_Train_label_40000_dist.npy')\n",
    "X=X.reshape(-1,1,64,64)\n",
    "I =np.arange(X.shape[0])\n",
    "np.random.shuffle(I)\n",
    "X_train=X[I[:int(0.75*X.shape[0])]]\n",
    "y_train=y[I[:int(0.75*X.shape[0])]]\n",
    "X_val=X[I[int(0.75*X.shape[0]):]]\n",
    "y_val=y[I[int(0.75*X.shape[0]):]]\n",
    "    \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class get_data(Dataset):\n",
    "    def __init__(self, data,label):\n",
    "        self.data = torch.FloatTensor(data.astype('float'))\n",
    "        self.label = torch.from_numpy(label).long()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.label.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_val = self.data[index]\n",
    "        target = self.label[index]\n",
    "        return data_val,target\n",
    "    \n",
    "batch_size = 100\n",
    "trainset = get_data(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "testset = get_data(X_val,y_val)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu\n",
      "epoch 1 Train loss: 0.666 | Acc: 80.527% (24158/30000)\n",
      "        Test loss: 0.149 | Acc: 96.660% (9666/10000)\n",
      "epoch 2 Train loss: 0.087 | Acc: 97.970% (29391/30000)\n",
      "        Test loss: 0.055 | Acc: 98.570% (9857/10000)\n",
      "epoch 3 Train loss: 0.035 | Acc: 99.273% (29782/30000)\n",
      "        Test loss: 0.022 | Acc: 99.450% (9945/10000)\n",
      "epoch 4 Train loss: 0.018 | Acc: 99.607% (29882/30000)\n",
      "        Test loss: 0.012 | Acc: 99.790% (9979/10000)\n",
      "epoch 5 Train loss: 0.011 | Acc: 99.803% (29941/30000)\n",
      "        Test loss: 0.007 | Acc: 99.880% (9988/10000)\n",
      "epoch 6 Train loss: 0.007 | Acc: 99.887% (29966/30000)\n",
      "        Test loss: 0.024 | Acc: 99.240% (9924/10000)\n",
      "epoch 7 Train loss: 0.006 | Acc: 99.833% (29950/30000)\n",
      "        Test loss: 0.007 | Acc: 99.810% (9981/10000)\n",
      "epoch 8 Train loss: 0.004 | Acc: 99.923% (29977/30000)\n",
      "        Test loss: 0.005 | Acc: 99.870% (9987/10000)\n",
      "epoch 9 Train loss: 0.003 | Acc: 99.960% (29988/30000)\n",
      "        Test loss: 0.003 | Acc: 99.930% (9993/10000)\n",
      "epoch 10 Train loss: 0.004 | Acc: 99.910% (29973/30000)\n",
      "        Test loss: 0.003 | Acc: 99.940% (9994/10000)\n",
      "epoch 11 Train loss: 0.003 | Acc: 99.943% (29983/30000)\n",
      "        Test loss: 0.002 | Acc: 99.950% (9995/10000)\n",
      "epoch 12 Train loss: 0.002 | Acc: 99.967% (29990/30000)\n",
      "        Test loss: 0.003 | Acc: 99.960% (9996/10000)\n",
      "epoch 13 Train loss: 0.003 | Acc: 99.930% (29979/30000)\n",
      "        Test loss: 0.007 | Acc: 99.750% (9975/10000)\n",
      "epoch 14 Train loss: 0.002 | Acc: 99.967% (29990/30000)\n",
      "        Test loss: 0.002 | Acc: 99.930% (9993/10000)\n",
      "epoch 15 Train loss: 0.002 | Acc: 99.957% (29987/30000)\n",
      "        Test loss: 0.002 | Acc: 99.940% (9994/10000)\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "features=[1,32,32,64,64,120,300]\n",
    "strides=[1,2]*3\n",
    "num_class=16\n",
    "\n",
    "net = ResNet(features, strides, num_class)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    net = net.cuda()\n",
    "    print(\"using gpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(net.parameters(),lr=0.0001)\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)\n",
    "    test(epoch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 64, 384)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Problems = np.load('Competition_Problems.npy')\n",
    "print(Problems.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! The first 10 problems have predicted scores: [ 9  1  0  0  0  0  1  5 10  1]\n"
     ]
    }
   ],
   "source": [
    "# segment data\n",
    "Nex = Problems.shape[0]\n",
    "dseg = 3\n",
    "thr = 0.0001\n",
    "X = np.sum(Problems,axis=1,keepdims=True)/np.sum(np.sum(Problems,axis=1,keepdims=True),axis=2,keepdims=True)\n",
    "\n",
    "First = np.zeros((Nex,1,64,64))\n",
    "Second = np.zeros((Nex,1,64,64))\n",
    "Third = np.zeros((Nex,1,64,64))\n",
    "for ex in range(Nex):\n",
    "    m = np.array(np.where(X[ex,0,64-dseg:2*64+dseg]>thr)).T\n",
    "    m2 = int(np.average(m+64-dseg))\n",
    "    First[ex,0,:,:] = Problems[ex,:,int(m2-32):int(m2+32)]\n",
    "    \n",
    "    m = np.array(np.where(X[ex,0,4*64-dseg:5*64+dseg]>thr)).T\n",
    "    m5 = int(np.average(m+4*64-dseg))\n",
    "    Second[ex,0,:,:] = Problems[ex,:,int(m5-32):int(m5+32)]\n",
    "    \n",
    "    Third[ex,0,:,:] = Problems[ex,:,int(384-64):384]\n",
    "\n",
    "\n",
    "\n",
    "# make predictions\n",
    "First=np.reshape(First,(-1,1,64,64))\n",
    "Second=np.reshape(Second,(-1,1,64,64))\n",
    "\n",
    "pred_First=np.zeros(First.shape[0])\n",
    "pred_Second=np.zeros(Second.shape[0])\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(int(200/1)):\n",
    "    syms=torch.FloatTensor(First[i*batch_size:(i+1)*batch_size].astype('float')).to(device)\n",
    "    T=net(syms).detach().cpu().numpy()    \n",
    "    pred_First[i*batch_size:(i+1)*batch_size]=np.argmax(T,1)\n",
    "    \n",
    "    syms=torch.FloatTensor(Second[i*batch_size:(i+1)*batch_size].astype('float')).to(device)\n",
    "    T=net(syms).detach().cpu().numpy()\n",
    "    pred_Second[i*batch_size:(i+1)*batch_size]=np.argmax(T,1)\n",
    "    \n",
    "# computing the score according to the grading rules \n",
    "A=(pred_First<4)\n",
    "B=(pred_First<7)*(pred_First>3)\n",
    "C=(pred_First>0)*A\n",
    "D7=(pred_Second-pred_First==7)\n",
    "D3=(pred_Second-pred_First==3)\n",
    "D12=(pred_Second-pred_First==12)\n",
    "D_3=(pred_Second-pred_First==-3)\n",
    "Score=(A*D7*10+B*D_3*10+A*D12*5+C*D3*2)*(np.sum(np.sum(Third[:,:,10:64],-1),-1)>200).reshape(-1,)\n",
    "Score += (A*D7*9+B*D_3*9+A*D12*5+C*D3*1)*(np.sum(np.sum(Third[:,:,10:64],-1),-1)<200).reshape(-1,)\n",
    "\n",
    "# Save the score as my_submission, which can be uploaded for the submission.\n",
    "np.save('joe_submission2.npy',Score)\n",
    "print('Done! The first 10 problems have predicted scores:', Score[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
